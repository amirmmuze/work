{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from common_functions.ipynb\n",
      "Importing Jupyter notebook from common_functions_message.ipynb\n",
      "Importing Jupyter notebook from common_functions_message.ipynb\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pprint\n",
    "from bson.objectid import ObjectId\n",
    "import pyperclip as clip\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import itertools\n",
    "# from datasu import auc\n",
    "# import pixiedust\n",
    "# clip.copy(json.dumps(m1['msg']))\n",
    "import nbimporter\n",
    "from common_functions import *\n",
    "from nbimporter import NotebookLoader\n",
    "loader = NotebookLoader()\n",
    "from common_functions_message import *\n",
    "Message = loader.load_module(\"common_functions_message\").Message\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_document(genie_message_id, genie_conversation_id, message_index, msg_vector, msg_repr_name, msg_repr_metadata, enc_metadata):\n",
    "    emb_metadata['shape'] = list(vector.shape)\n",
    "    emb_metadata['msg_repr'] = msg_repr_metadata\n",
    "    \n",
    "    emb_doc = {        \n",
    "        'genie_conversation_message_id': genie_message_id, \n",
    "        'genie_conversation_id':genie_conversation_id,\n",
    "        'message_index': message_index,         \n",
    "        \n",
    "        'msg_vector': msg_vector,       \n",
    "        \n",
    "        'emb_metadata': emb_metadata,        \n",
    "        'enc_metadata': enc_metadata\n",
    "    }\n",
    "    return emb_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONGO_HOST = \"ec2-52-23-187-115.compute-1.amazonaws.com\"\n",
    "MONGO_DB = \"marketpulzz\"\n",
    "# server = SSHTunnelForwarder(\n",
    "#     MONGO_HOST,\n",
    "#     ssh_username='ubuntu',\n",
    "#     ssh_pkey=\"/Users/sasha/.ssh/mmuze.pem\",\n",
    "# #     ssh_private_key_password=\"secret\",\n",
    "#     remote_bind_address=('127.0.0.1', 27017),\n",
    "#     local_bind_address=('127.0.0.1', 63328),\n",
    "#     set_keepalive = 5,\n",
    "# )\n",
    "\n",
    "# server.start()\n",
    "# client = MongoClient('127.0.0.1', server.local_bind_port) # server.local_bind_port is assigned local port\n",
    "# db = client[MONGO_DB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_local = MongoClient('127.0.0.1', 27017)\n",
    "db_local = client_local[MONGO_DB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection={'msg.text':1, '_id':1, 'conversation_id':1,'message_index':1}\n",
    "skip=0\n",
    "# genie_conversation_messages_cursor = db_local.genie_conversation_messages.find({}, projection=projection)[skip:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk #: 1, chunk_len: 400\n",
      "chunk #: 2, chunk_len: 400\n",
      "chunk #: 3, chunk_len: 400\n",
      "chunk #: 4, chunk_len: 400\n",
      "chunk #: 5, chunk_len: 400\n",
      "chunk #: 6, chunk_len: 400\n",
      "chunk #: 7, chunk_len: 281\n",
      "total docs iterated:  2681\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embed messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /var/folders/xn/dh4vn2gx4x36vh0x051kpw1m0000gn/T/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/3'.\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 30.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 70.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 100.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 130.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 170.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 200.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 230.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 260.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 290.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 320.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 350.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 390.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 430.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 470.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 510.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 550.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 580.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 620.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 660.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 700.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 740.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3: 780.00MB\n",
      "INFO:tensorflow:Downloaded https://tfhub.dev/google/universal-sentence-encoder-large/3, Total size: 810.60MB\n",
      "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/3'.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/48092772/add-operation-to-graph-without-with-as-clause\n",
    "import tensorflow_hub as hub\n",
    "graph = tf.Graph()\n",
    "cm = graph.as_default()   \n",
    "cm.__enter__()\n",
    "# module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" \n",
    "model_USE = 'universal-sentence-encoder-large/3'\n",
    "module_url = f\"https://tfhub.dev/google/{model_USE}\" \n",
    "#@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url, trainable=True)\n",
    "\n",
    "session = tf.Session(graph=graph)\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.tables_initializer())\n",
    "input1 = tf.placeholder(tf.string, shape=(None))\n",
    "emb = embed(input1)\n",
    "\n",
    "\n",
    "def encode_USE(texts):   \n",
    "    emb1 = session.run([emb], feed_dict={ input1: texts })\n",
    "    return emb1\n",
    "\n",
    "#warm up\n",
    "_ = encode_USE([\"sasha\", \"miko\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_metadata = {    \n",
    "    'encoder': 'USE',    \n",
    "    'model': model_USE,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_metadata = {\n",
    "    'fields': [{'msg.text':'emb(msg.text)'}],\n",
    "    'repr_key': 'emb_text1'\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mess_chunk_iter = iterate_by_chunks(db_local.genie_conversation_messages, 400, 0, query={}, projection=projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_emb_document(genie_message_id, genie_conversation_id, message_index, msg_vector, msg_repr_name, msg_repr_metadata, enc_metadata):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_n=0\n",
    "total_docs=0\n",
    "for docs in mess_chunk_iter:\n",
    "    chunk_n=chunk_n+1        \n",
    "    chunk_len = 0\n",
    "    for d in docs:\n",
    "        chunk_len=chunk_len+1\n",
    "        total_docs=total_docs+1\n",
    "    print(f'chunk #: {chunk_n}, chunk_len: {chunk_len}')\n",
    "\n",
    "print(\"total docs iterated: \", total_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 47s, sys: 1min 22s, total: 12min 10s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emb_USE = encode_USE(texts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_emb_cache = list(map(lambda t: create_emb_cached_value(t[0],t[1].tolist(),use_metadata) ,zip(texts, emb_USE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/opt/pyenv/versions/anaconda3-5.3.0/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: save is deprecated. Use insert_one or replace_one instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for m in use_emb_cache:\n",
    "    db_local.embeddings_cache.save(m, check_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-serving-start -model_dir /Users/sasha/dev/mmuze/_models/BERT/uncased_L-12_H-768_A-12 -num_worker=1 -max_batch_size 16 -max_seq_len 200 -pooling_strategy REDUCE_MEAN -pooling_layer -5\n"
     ]
    }
   ],
   "source": [
    "#bert-serving-start -model_dir /Users/sasha/dev/mmuze/_models/BERT/uncased_L-12_H-768_A-12/ -num_worker=1 -max_batch_size 16 -max_seq_len 200 -pooling_strategy REDUCE_MEAN -pooling_layer -2 \n",
    "bert_metadata = {            \n",
    "    'version': '1.0',\n",
    "    'encoder': 'BERT',\n",
    "    'model': 'uncased_L-12_H-768_A-12',    \n",
    "    'max_seq_len': 200,\n",
    "    'pooling_strategy': 'REDUCE_MEAN', \n",
    "    'pooling_layer': '-5',\n",
    "#     'dimensions': emb_bert[0].shape[0]\n",
    "}\n",
    "\n",
    "print(f\"bert-serving-start \\\n",
    "-model_dir /Users/sasha/dev/mmuze/_models/BERT/{bert_metadata['model']} \\\n",
    "-num_worker=1 \\\n",
    "-max_batch_size 16 \\\n",
    "-max_seq_len {bert_metadata['max_seq_len']} \\\n",
    "-pooling_strategy {bert_metadata['pooling_strategy']} \\\n",
    "-pooling_layer {bert_metadata['pooling_layer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 149 ms, sys: 42.4 ms, total: 191 ms\n",
      "Wall time: 12min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emb_bert = bc.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_emb_cache = list(map(lambda t: create_emb_cached_value(t[0],t[1].tolist(),bert_metadata) ,zip(texts, emb_bert)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/opt/pyenv/versions/anaconda3-5.3.0/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: save is deprecated. Use insert_one or replace_one instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for m in bert_emb_cache:\n",
    "    db_local.embeddings_cache.save(m, check_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2818"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_emb_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = get_embedding_from_cache('', use_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
