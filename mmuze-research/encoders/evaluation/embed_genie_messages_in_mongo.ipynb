{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from common_functions.ipynb\n",
      "Importing Jupyter notebook from common_functions_message.ipynb\n",
      "Importing Jupyter notebook from common_functions_message.ipynb\n",
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pprint\n",
    "from bson.objectid import ObjectId\n",
    "import pyperclip as clip\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import itertools\n",
    "import time\n",
    "# from datasu import auc\n",
    "# import pixiedust\n",
    "# clip.copy(json.dumps(m1['msg']))\n",
    "import nbimporter\n",
    "from common_functions import *\n",
    "from nbimporter import NotebookLoader\n",
    "loader = NotebookLoader()\n",
    "from common_functions_message import *\n",
    "Message = loader.load_module(\"common_functions_message\").Message\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_document(timestamp, genie_message_id, genie_conversation_id, message_index, msg_vector, msg_rpr_key, rpr_metadata, enc_metadata):    \n",
    "    msg_rpr_metadata = {\n",
    "        'shape': list(msg_vector.shape),\n",
    "        'msg_rpr': rpr_metadata,\n",
    "    }\n",
    "    \n",
    "    emb_doc = {        \n",
    "        'genie_conversation_message_id': genie_message_id, \n",
    "        'genie_conversation_id':genie_conversation_id,\n",
    "        'message_index': message_index,    \n",
    "        'rpr_key': msg_rpr_key,\n",
    "        'version': timestamp,\n",
    "        \n",
    "        'msg_vector': msg_vector.tolist(),       \n",
    "        \n",
    "        'rpr_metadata': msg_rpr_metadata,        \n",
    "        'enc_metadata': enc_metadata\n",
    "    }\n",
    "    return emb_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_genie_messages(db, msg_chunk_iterator, msg_rpr_key, rpr_metadata, enc_metadata, msgs_to_vector_delegate):\n",
    "    chunk_n=0\n",
    "    total_docs=0\n",
    "    # ppp = []\n",
    "\n",
    "    timestamp = time.time()\n",
    "\n",
    "    for docs in msg_chunk_iterator:\n",
    "        chunk_n=chunk_n+1        \n",
    "        chunk_len = 0   \n",
    "        msgs = list(docs)\n",
    "\n",
    "        emb_vectors = msgs_to_vector_delegate(msgs)\n",
    "\n",
    "        def de(msg, msg_vector):\n",
    "            return create_emb_document(timestamp, msg['_id'], msg['conversation_id'], msg['message_index'], msg_vector, msg_rpr_key, rpr_metadata, enc_metadata)        \n",
    "        msg_emb_docs = [de(msg, msg_vector) for msg,msg_vector in zip(msgs, emb_vectors)]\n",
    "\n",
    "        for emb_doc in msg_emb_docs:\n",
    "            f = {\n",
    "                'genie_conversation_message_id': emb_doc['genie_conversation_message_id'],\n",
    "                'genie_conversation_id': emb_doc['genie_conversation_id'],\n",
    "                'message_index': emb_doc['message_index'],\n",
    "                'rpr_key': emb_doc['rpr_key'],            \n",
    "            }\n",
    "            db.genie_conversation_messages_embs.replace_one(f, emb_doc, upsert=True)\n",
    "\n",
    "    #         db_local.genie_conversation_messages_embs.insert_many(msg_emb_docs)\n",
    "\n",
    "        chunk_len=chunk_len+len(msg_emb_docs)\n",
    "        total_docs=total_docs+len(msg_emb_docs)\n",
    "        print(f'chunk #: {chunk_n}, chunk_len: {chunk_len}')\n",
    "\n",
    "    print(\"total docs iterated: \", total_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONGO_HOST = \"ec2-52-23-187-115.compute-1.amazonaws.com\"\n",
    "MONGO_DB = \"marketpulzz\"\n",
    "# server = SSHTunnelForwarder(\n",
    "#     MONGO_HOST,\n",
    "#     ssh_username='ubuntu',\n",
    "#     ssh_pkey=\"/Users/sasha/.ssh/mmuze.pem\",\n",
    "# #     ssh_private_key_password=\"secret\",\n",
    "#     remote_bind_address=('127.0.0.1', 27017),\n",
    "#     local_bind_address=('127.0.0.1', 63328),\n",
    "#     set_keepalive = 5,\n",
    "# )\n",
    "\n",
    "# server.start()\n",
    "# client = MongoClient('127.0.0.1', server.local_bind_port) # server.local_bind_port is assigned local port\n",
    "# db = client[MONGO_DB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_local = MongoClient('127.0.0.1', 27017)\n",
    "db_local = client_local[MONGO_DB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection={'msg.text':1, '_id':1, 'conversation_id':1,'message_index':1}\n",
    "skip=0\n",
    "# genie_conversation_messages_cursor = db_local.genie_conversation_messages.find({}, projection=projection)[skip:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embed messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /var/folders/xn/dh4vn2gx4x36vh0x051kpw1m0000gn/T/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/48092772/add-operation-to-graph-without-with-as-clause\n",
    "import tensorflow_hub as hub\n",
    "graph = tf.Graph()\n",
    "cm = graph.as_default()   \n",
    "cm.__enter__()\n",
    "# module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" \n",
    "model_USE = 'universal-sentence-encoder-large/3'\n",
    "module_url = f\"https://tfhub.dev/google/{model_USE}\" \n",
    "#@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url, trainable=True)\n",
    "\n",
    "session = tf.Session(graph=graph)\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.tables_initializer())\n",
    "input1 = tf.placeholder(tf.string, shape=(None))\n",
    "emb = embed(input1)\n",
    "\n",
    "\n",
    "def encode_USE(texts):   \n",
    "    emb1 = session.run([emb], feed_dict={ input1: texts })\n",
    "    return emb1\n",
    "\n",
    "#warm up\n",
    "_ = encode_USE([\"sasha\", \"miko\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "def _embed_messages_text_use_1(msg_bsons):    \n",
    "    texts = list(map(lambda msg: msg['msg']['text'], msg_bsons))    \n",
    "    emb_USE = encode_USE(texts)[0]     \n",
    "    return emb_USE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_metadata = {    \n",
    "    'encoder': 'USE',    \n",
    "    'model': model_USE,    \n",
    "}\n",
    "rpr_metadata = {\n",
    "    'fields': [{'field':'msg.text', 'emb':'emb(msg.text)'}],    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_len_filter = {'$where': 'this.msg.text.length > 1'}\n",
    "query={**text_len_filter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$where': 'this.msg.text.length > 1'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_len_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mess_chunk_iter = iterate_by_chunks(db_local.genie_conversation_messages, chunksize=100, start_from=0, query=query, projection=projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk #: 1, chunk_len: 100\n",
      "chunk #: 2, chunk_len: 100\n",
      "chunk #: 3, chunk_len: 100\n",
      "chunk #: 4, chunk_len: 100\n",
      "chunk #: 5, chunk_len: 100\n",
      "chunk #: 6, chunk_len: 100\n",
      "chunk #: 7, chunk_len: 100\n",
      "chunk #: 8, chunk_len: 100\n",
      "chunk #: 9, chunk_len: 100\n",
      "chunk #: 10, chunk_len: 100\n",
      "chunk #: 11, chunk_len: 100\n",
      "chunk #: 12, chunk_len: 100\n",
      "chunk #: 13, chunk_len: 100\n",
      "chunk #: 14, chunk_len: 100\n",
      "chunk #: 15, chunk_len: 100\n",
      "chunk #: 16, chunk_len: 100\n",
      "chunk #: 17, chunk_len: 100\n",
      "chunk #: 18, chunk_len: 100\n",
      "chunk #: 19, chunk_len: 100\n",
      "chunk #: 20, chunk_len: 100\n",
      "chunk #: 21, chunk_len: 100\n",
      "chunk #: 22, chunk_len: 100\n",
      "chunk #: 23, chunk_len: 100\n",
      "chunk #: 24, chunk_len: 100\n",
      "chunk #: 25, chunk_len: 100\n",
      "chunk #: 26, chunk_len: 100\n",
      "chunk #: 27, chunk_len: 81\n",
      "total docs iterated:  2681\n"
     ]
    }
   ],
   "source": [
    "embed_genie_messages(db_local, mess_chunk_iter, 'text.use.1', rpr_metadata, use_metadata, _embed_messages_text_use_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-serving-start -model_dir /Users/sasha/dev/mmuze/_models/BERT/uncased_L-12_H-768_A-12 -num_worker=1 -max_batch_size 16 -max_seq_len 200 -pooling_strategy REDUCE_MEAN -pooling_layer -5\n"
     ]
    }
   ],
   "source": [
    "#bert-serving-start -model_dir /Users/sasha/dev/mmuze/_models/BERT/uncased_L-12_H-768_A-12/ -num_worker=1 -max_batch_size 16 -max_seq_len 200 -pooling_strategy REDUCE_MEAN -pooling_layer -2 \n",
    "bert_metadata = {            \n",
    "    'version': '1.0',\n",
    "    'encoder': 'BERT',\n",
    "    'model': 'uncased_L-12_H-768_A-12',    \n",
    "    'max_seq_len': 200,\n",
    "    'pooling_strategy': 'REDUCE_MEAN', \n",
    "    'pooling_layer': '-5',\n",
    "#     'dimensions': emb_bert[0].shape[0]\n",
    "}\n",
    "\n",
    "print(f\"bert-serving-start \\\n",
    "-model_dir /Users/sasha/dev/mmuze/_models/BERT/{bert_metadata['model']} \\\n",
    "-num_worker=1 \\\n",
    "-max_batch_size 16 \\\n",
    "-max_seq_len {bert_metadata['max_seq_len']} \\\n",
    "-pooling_strategy {bert_metadata['pooling_strategy']} \\\n",
    "-pooling_layer {bert_metadata['pooling_layer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpr_metadata = {\n",
    "    'fields': [{'field':'msg.text', 'emb':'emb(msg.text)'}],    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _embed_messages_text_bert_1(msg_bsons):    \n",
    "    texts = list(map(lambda msg: msg['msg']['text'], msg_bsons))    \n",
    "    emb_bert = bc.encode(texts) \n",
    "    return emb_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mess_chunk_iter = iterate_by_chunks(db_local.genie_conversation_messages, chunksize=100, start_from=0, query=query, projection=projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk #: 1, chunk_len: 100\n",
      "chunk #: 2, chunk_len: 100\n",
      "chunk #: 3, chunk_len: 100\n",
      "chunk #: 4, chunk_len: 100\n",
      "chunk #: 5, chunk_len: 100\n",
      "chunk #: 6, chunk_len: 100\n",
      "chunk #: 7, chunk_len: 100\n",
      "chunk #: 8, chunk_len: 100\n",
      "chunk #: 9, chunk_len: 100\n",
      "chunk #: 10, chunk_len: 100\n",
      "chunk #: 11, chunk_len: 100\n",
      "chunk #: 12, chunk_len: 100\n",
      "chunk #: 13, chunk_len: 100\n",
      "chunk #: 14, chunk_len: 100\n",
      "chunk #: 15, chunk_len: 100\n",
      "chunk #: 16, chunk_len: 100\n",
      "chunk #: 17, chunk_len: 100\n",
      "chunk #: 18, chunk_len: 100\n",
      "chunk #: 19, chunk_len: 100\n",
      "chunk #: 20, chunk_len: 100\n",
      "chunk #: 21, chunk_len: 100\n",
      "chunk #: 22, chunk_len: 100\n",
      "chunk #: 23, chunk_len: 100\n",
      "chunk #: 24, chunk_len: 100\n",
      "chunk #: 25, chunk_len: 100\n",
      "chunk #: 26, chunk_len: 100\n",
      "chunk #: 27, chunk_len: 81\n",
      "total docs iterated:  2681\n"
     ]
    }
   ],
   "source": [
    "embed_genie_messages(mess_chunk_iter, 'text.bert.1', rpr_metadata, use_metadata, _embed_messages_text_bert_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_emb_cache = list(map(lambda t: create_emb_cached_value(t[0],t[1].tolist(),bert_metadata) ,zip(texts, emb_bert)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in bert_emb_cache:\n",
    "    db_local.embeddings_cache.save(m, check_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bert_emb_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = get_embedding_from_cache('', use_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
