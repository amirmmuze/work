{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pprint\n",
    "from bson.objectid import ObjectId\n",
    "import pyperclip as clip\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from functools import partial\n",
    "# from datasu import auc\n",
    "# import pixiedust\n",
    "# clip.copy(json.dumps(m1['msg']))\n",
    "import sys\n",
    "# sys.path.append(\"..\")\n",
    "from random import shuffle\n",
    "import nbimporter\n",
    "# from nbimporter import NotebookLoader\n",
    "# loader = NotebookLoader(\"..\")\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# from angie.service.app_config import AppConfig\n",
    "from angie.datacontracts.msg_similarity import SimilarityMeasure\n",
    "from angie.libs.tensorflow_utils import sim_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from angie.libs.singleton import singleton\n",
    "from angie.libs.mongo_utils import iterate_by_chunks\n",
    "from angie.datacontracts.msg_similarity import *\n",
    "from angie.datacontracts.msg import Message\n",
    "from angie.libs.tensorflow_utils import sim_exact\n",
    "\n",
    "from angie.datacontracts.http.msg_filter import MsgFilter\n",
    "from angie.datacontracts.http.msg_representation_response import MsgEmbRepresentationResponse\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from typing import List\n",
    "from angie.libs.singleton import singleton\n",
    "from bert_serving.client import BertClient\n",
    "from numpy import ndarray\n",
    "\n",
    "class MsgEmbRepresentation:\n",
    "    def __init__(self, genie_msg_id: str, msg_vector: ndarray):\n",
    "        self.genie_msg_id = genie_msg_id\n",
    "        self.msg_vector = msg_vector#.tolist()\n",
    "\n",
    "class GenieMsgManager(object):\n",
    "\n",
    "    def __init__(self, db=None):\n",
    "        self.db = db\n",
    "\n",
    "\n",
    "    def getMessagesForIds(self, genie_ids: List[str]) -> List[Message]:\n",
    "        genie_obj_ids = list(map(ObjectId, genie_ids))\n",
    "        filter = {'_id': {'$in': genie_obj_ids}}\n",
    "        msgs_cursor = self.db.genie_conversation_messages.find(filter)\n",
    "        msgs = list(map(lambda m: Message(m), msgs_cursor))\n",
    "        return msgs\n",
    "\n",
    "    def getMessageById(self, genie_id: str) -> Message:\n",
    "        filter = {'_id': ObjectId(genie_id)}\n",
    "        msg_hash = self.db.genie_conversation_messages.find_one(filter)\n",
    "        if msg_hash:\n",
    "            msg = Message(msg_hash)\n",
    "            return msg\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "@singleton\n",
    "class EmbeddingModelWrapper_BERT:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.bert_client = BertClient()\n",
    "\n",
    "    def embed(self, texts: List[str]):\n",
    "        emb = self.bert_client.encode(texts)\n",
    "        return emb\n",
    "\n",
    "\n",
    "\n",
    "class BaseMsgRprConvertor(ABC):\n",
    "    def __init__(self, msg: Message):\n",
    "        self.msg = msg\n",
    "        super().__init__()\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_rpr(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class MsgRprConvertor_Text_BERT(BaseMsgRprConvertor):\n",
    "\n",
    "    def get_rpr(self):        \n",
    "        text = self.msg.get_text()\n",
    "        msg_vector = EmbeddingModelWrapper_BERT().embed([text])[0]\n",
    "        return msg_vector\n",
    "\n",
    "class MsgSimilarityManager(object):\n",
    "\n",
    "    def __init__(self, db=None):\n",
    "        self.db = db\n",
    "        self.genie_msg_manager = GenieMsgManager(self.db)\n",
    "\n",
    "\n",
    "    def getEmbRepresForMessages(self, messages: List[Message], rpr_key: str) -> List[MsgEmbRepresentation]:        \n",
    "        rpr_conv = MsgRprConvertor_Text_BERT\n",
    "        msg_reprs = list(map(lambda m: MsgEmbRepresentation(m.get_genie_id(), rpr_conv(m).get_rpr()), messages))\n",
    "        return msg_reprs\n",
    "\n",
    "\n",
    "    def getEmbRepresForIds(self, genie_ids: list, rpr_key: str) -> List[MsgEmbRepresentation]:\n",
    "        messages = self.genie_msg_manager.getMessagesForIds(genie_ids)\n",
    "        msg_reprs = self.getEmbRepresForMessages(messages, rpr_key)\n",
    "        return msg_reprs\n",
    "\n",
    "\n",
    "    def getTopKSimilarMsgsForMsg(self, genie_id: str, K: int, rpr_key: str, sim_measure: SimilarityMeasure, messages_filter: MsgFilter=None, chunk_size=10000)-> List[MsgSimilarity]:\n",
    "        genie_msg = self.genie_msg_manager.getMessageById(genie_id)\n",
    "        if genie_msg:\n",
    "            msg_rpr = self.getEmbRepresForMessages([genie_msg], rpr_key)[0]\n",
    "            k_sims_all = self.getTopKSimilarMsgsForQueryVector(msg_rpr.msg_vector, K + 1, rpr_key, sim_measure, messages_filter=messages_filter, chunk_size=chunk_size)\n",
    "            k_sims = list(filter(lambda ms: ms.genie_msg_id != genie_id, k_sims_all))\n",
    "            return k_sims\n",
    "        else:\n",
    "            return list()\n",
    "\n",
    "\n",
    "    def getTopKSimilarMsgsForText(self, query_text: str, K: int, rpr_key: str, sim_measure: SimilarityMeasure, messages_filter: MsgFilter = None, chunk_size=10000) -> List[MsgSimilarity]:\n",
    "        query_vector = {            \n",
    "            'text_bert_1': lambda q: self.embedTextsBERT([q])[0]\n",
    "        }.get(rpr_key)(query_text),\n",
    "        k_sims = self.getTopKSimilarMsgsForQueryVector(query_vector[0], K, rpr_key, sim_measure, messages_filter=messages_filter, chunk_size=chunk_size)\n",
    "        return k_sims\n",
    "\n",
    "\n",
    "    def getTopKSimilarMsgsForQueryVector(self, query_vector: np.ndarray, K: int, rpr_key: str, sim_measure: SimilarityMeasure, messages_filter: MsgFilter=None, chunk_size=10000) -> List[MsgSimilarity]:\n",
    "\n",
    "        _chunk_size = max(K, chunk_size)\n",
    "        msg_embs_iter = iterate_by_chunks(self.db.genie_conversation_messages_embs, chunksize=_chunk_size, start_from=0,\n",
    "                                            query={'rpr_key':rpr_key}, projection={ 'msg_vector':1, 'genie_conversation_message_id':1 })\n",
    "        top_k_similar = []\n",
    "        chunk_n = 0\n",
    "        for msg_embs_cursor in msg_embs_iter:\n",
    "            chunk_n = chunk_n + 1\n",
    "\n",
    "            try:\n",
    "                msgs_embs_docs = list(msg_embs_cursor)\n",
    "                msg_vectors = list(map(lambda me: me['msg_vector'], msgs_embs_docs))\n",
    "\n",
    "                sims_res = sim_exact([query_vector], np.array(msg_vectors))\n",
    "\n",
    "                sim_scores = {\n",
    "                    SimilarityMeasure.ANGDIST: sims_res[0],\n",
    "                    SimilarityMeasure.COSSIM: sims_res[1]\n",
    "                }.get(sim_measure)  # , lambda z: raise_(ValueError(f\"{sim_measure} not implemented\")))\n",
    "\n",
    "                msg_sims = [MsgSimilarity(str(msg['genie_conversation_message_id']), float(sim_score[0])) for msg, sim_score in zip(msgs_embs_docs, sim_scores)]\n",
    "\n",
    "                k_similar = list(sorted(top_k_similar + msg_sims, key=lambda ms: ms.similarity_score ,reverse=True))\n",
    "                top_k_similar = k_similar[:K]\n",
    "\n",
    "                print(f'chunk #: {chunk_n}, chunk_len: {len(msgs_embs_docs)}')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        return top_k_similar\n",
    "\n",
    "    # region Patch methods to treat to partially treat imports conflicts of BERT and USE\n",
    "\n",
    "    def embedTextsBERT(self, texts: List[str]):\n",
    "        \"\"\"\n",
    "        This is patch method to partially treat imports conflicts of BERT and USE\n",
    "        \"\"\"        \n",
    "        vector = EmbeddingModelWrapper_BERT().embed(texts)\n",
    "        return vector\n",
    "\n",
    "\n",
    "    \n",
    "    # endregion\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_messages(n, rpr_key):\n",
    "    fltr = {'rpr_key':rpr_key}\n",
    "    embs_len = db.genie_conversation_messages_embs.find(fltr).count();\n",
    "    random_ints = np.random.randint(0,embs_len, n)\n",
    "    msgs_embs = []\n",
    "    for r_ind in random_ints.tolist():\n",
    "        rnd_msg_emb = list(db.genie_conversation_messages_embs.find(fltr).skip(r_ind).limit(1))[0];\n",
    "        msgs_embs.append(rnd_msg_emb)\n",
    "\n",
    "    msg_ids = map(lambda ms: ms['genie_conversation_message_id'], msgs_embs)\n",
    "    msgs = gniMsgManager.getMessagesForIds(msg_ids)\n",
    "\n",
    "    random_msg_vectors = [{'text': msg.get_text(), 'vector': np.array(msg_emb['msg_vector'])} for msg_emb, msg in zip(msgs_embs, msgs)]   \n",
    "    \n",
    "    return random_msg_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cands_for_query(rpr_key, row):\n",
    "    \n",
    "#     import pdb; pdb.set_trace()\n",
    "    \n",
    "    K = 10\n",
    "    query_vector = np.array(row['q_vector'])\n",
    "    query = row['query']\n",
    "    if 'genie_conversation_message_id' in row:\n",
    "        query_mess_id = row['genie_conversation_message_id']\n",
    "        sims = msgSimManager.get_top_k_similar_msgs_for_msg(query_mess_id, K*100, rpr_key, SimilarityMeasure.ANGDIST, chunk_size=10000)\n",
    "    else:                \n",
    "        sims = msgSimManager.get_top_k_similar_msgs_for_text(query, K*5, rpr_key, SimilarityMeasure.ANGDIST, chunk_size=10000)        \n",
    "    \n",
    "    sims_ids = list(map(lambda ms: ms.genie_msg_id, sims))\n",
    "    sim_msgs = gniMsgManager.get_messages_by_ids(sims_ids)        \n",
    "    sim_msgs_texts = [{'query': query, 'text': msg.get_text().strip(), 'sim_score': sim.similarity_score, 'is_random':False}  for sim, msg in zip(sims, sim_msgs)]\n",
    "    \n",
    "    sim_msgs_texts_K = set(sorted(filter(lambda sm: sm['text'] != query, sim_msgs_texts), key=lambda sm: sm['sim_score'], reverse=True))[0:K]\n",
    "            \n",
    "\n",
    "    rnd_msg_vectors = get_random_messages(K, rpr_key)    \n",
    "    rnd_vectors= list(map(lambda m_v: m_v['vector'], rnd_msg_vectors))     \n",
    "    query_rnd_sims = sim_exact([query_vector] ,rnd_vectors)[0].squeeze()\n",
    "    rnd_msgs_texts = [{'query': query, 'text': msg['text'], 'sim_score': similarity_score, 'is_random':True} for similarity_score, msg in zip(query_rnd_sims, rnd_msg_vectors)]\n",
    "    \n",
    "    all_cand_msgs = sim_msgs_texts_K+rnd_msgs_texts    \n",
    "    shuffle(all_cand_msgs)\n",
    "    return all_cand_msgs\n",
    "    \n",
    "#     return pd.DataFrame(sim_msgs_texts+rnd_msgs_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/sasha/temp/STS2'\n",
    "\n",
    "encoder_name = 'BERT'\n",
    "rpr_key = 'text_bert_1'\n",
    "encoder = EmbeddingModelWrapper_BERT()\n",
    "\n",
    "# encoder_name = 'USE'\n",
    "# rpr_key = 'text_use_1'\n",
    "# from angie.libs.embed.embedding_model_wrapper_use import EmbeddingModelWrapper_USE\n",
    "# encoder = EmbeddingModelWrapper_USE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONGO_HOST = 'ec2-52-23-187-115.compute-1.amazonaws.com'\n",
    "# MONGO_DB = \"marketpulzz\"\n",
    "# server = SSHTunnelForwarder(\n",
    "#     MONGO_HOST,\n",
    "#     ssh_username='ubuntu',\n",
    "#     ssh_pkey=\"/Users/sasha/.ssh/mmuze.pem\",\n",
    "# #     ssh_private_key_password=\"secret\",\n",
    "#     remote_bind_address=('127.0.0.1', 27017),\n",
    "#     local_bind_address=('127.0.0.1', 63329),\n",
    "#     set_keepalive = 5,\n",
    "# )\n",
    "\n",
    "# server.start()\n",
    "# client = MongoClient('127.0.0.1', server.local_bind_port) # server.local_bind_port is assigned local port\n",
    "# db = client[MONGO_DB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_DB = \"marketpulzz\"\n",
    "client = MongoClient('127.0.0.1', 27017)\n",
    "\n",
    "# read_preference = ReadPreference.PRIMARY\n",
    "# mongo_hosts : [\"ec2-52-23-187-115.compute-1.amazonaws.com:27017\", \"ec2-52-90-96-8.compute-1.amazonaws.com:27017\"]\n",
    "# client = MongoClient(mongo_hosts, read_preference = read_preference)\n",
    "\n",
    "db = client[MONGO_DB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgSimManager = MsgSimilarityManager(db)\n",
    "gniMsgManager = GenieMsgManager(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_input_path = f'{path}/STS2_queries.xlsx'\n",
    "output_path = f'{path}/STS2_{encoder_name}-v1.0.xlsx'\n",
    "df_queries = pd.read_excel(query_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries['q_vector'] = encoder.embed(df_queries['query'].tolist()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/opt/pyenv/versions/anaconda3-5.3.0/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk #: 1, chunk_len: 2681\n",
      "chunk #: 1, chunk_len: 2681\n"
     ]
    }
   ],
   "source": [
    "sts2_rows_lists = df_queries.apply(partial(get_cands_for_query, rpr_key), axis=1)\n",
    "sts2_rows =list(it.chain(*sts2_rows_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sts2 = pd.DataFrame(sts2_rows)\n",
    "df_sts2.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
