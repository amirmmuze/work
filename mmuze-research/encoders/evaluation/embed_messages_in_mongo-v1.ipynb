{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from common_functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pprint\n",
    "from bson.objectid import ObjectId\n",
    "import pyperclip as clip\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "# from datasu import auc\n",
    "# import pixiedust\n",
    "# clip.copy(json.dumps(m1['msg']))\n",
    "import nbimporter\n",
    "from common_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONGO_HOST = \"ec2-52-23-187-115.compute-1.amazonaws.com\"\n",
    "MONGO_DB = \"marketpulzz\"\n",
    "# server = SSHTunnelForwarder(\n",
    "#     MONGO_HOST,\n",
    "#     ssh_username='ubuntu',\n",
    "#     ssh_pkey=\"/Users/sasha/.ssh/mmuze.pem\",\n",
    "# #     ssh_private_key_password=\"secret\",\n",
    "#     remote_bind_address=('127.0.0.1', 27017),\n",
    "#     local_bind_address=('127.0.0.1', 63328),\n",
    "#     set_keepalive = 5,\n",
    "# )\n",
    "\n",
    "# server.start()\n",
    "# client = MongoClient('127.0.0.1', server.local_bind_port) # server.local_bind_port is assigned local port\n",
    "# db = client[MONGO_DB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_local = MongoClient('127.0.0.1', 27017)\n",
    "db_local = client_local[MONGO_DB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = list(db_local.genie_conversation_messages_emb.find({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(map(lambda m: m['msg']['text'], messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = np.array(list((map(lambda t: len(t.split(' ')), texts))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.45244311823946, 198, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.mean(), lengths.max(), lengths.min(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1818,  618,  160,   43,   26,   11,    3,    1,    0,    1]),\n",
       " array([  1. ,  20.7,  40.4,  60.1,  79.8,  99.5, 119.2, 138.9, 158.6,\n",
       "        178.3, 198. ]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embed messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_emb_to_message(message, field_name, vector, metadata):\n",
    "    current_embs = message.get('embs', {})\n",
    "    field_embs = current_embs.get(field_name, [])   \n",
    "    embd_data = {**metadata, 'vector':vector.tolist()}    \n",
    "    field_embs.append(embd_data)\n",
    "    current_embs[field_name] = field_embs\n",
    "    message['embs'] = current_embs\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-serving-start -model_dir /Users/sasha/dev/mmuze/_models/BERT/uncased_L-12_H-768_A-12 -num_worker=1 -max_batch_size 16 -max_seq_len 200 -pooling_strategy REDUCE_MEAN -pooling_layer -5\n"
     ]
    }
   ],
   "source": [
    "#bert-serving-start -model_dir /Users/sasha/dev/mmuze/_models/BERT/uncased_L-12_H-768_A-12/ -num_worker=1 -max_batch_size 16 -max_seq_len 200 -pooling_strategy REDUCE_MEAN -pooling_layer -2 \n",
    "metadata = {            \n",
    "    'version': '1.0',\n",
    "    'encoder': 'BERT',\n",
    "    'model': 'uncased_L-12_H-768_A-12',    \n",
    "    'max_seq_len': 200,\n",
    "    'pooling_strategy': 'REDUCE_MEAN', \n",
    "    'pooling_layer': '-5',\n",
    "#     'dimensions': emb_bert[0].shape[0]\n",
    "}\n",
    "\n",
    "print(f\"bert-serving-start \\\n",
    "-model_dir /Users/sasha/dev/mmuze/_models/BERT/{metadata['model']} \\\n",
    "-num_worker=1 \\\n",
    "-max_batch_size 16 \\\n",
    "-max_seq_len {metadata['max_seq_len']} \\\n",
    "-pooling_strategy {metadata['pooling_strategy']} \\\n",
    "-pooling_layer {metadata['pooling_layer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 139 ms, sys: 48.5 ms, total: 187 ms\n",
      "Wall time: 11min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emb_bert = bc.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_emb = list(map(lambda mess_emb: add_emb_to_message(mess_emb[0], 'text', mess_emb[1], metadata), zip(messages.copy(),emb_bert)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/opt/pyenv/versions/anaconda3-5.3.0/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: save is deprecated. Use insert_one or replace_one instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for m in messages_emb:\n",
    "    db_local.genie_conversation_messages_emb.save(m, check_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = messages_emb[0]['embs']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/48092772/add-operation-to-graph-without-with-as-clause\n",
    "import tensorflow_hub as hub\n",
    "graph = tf.Graph()\n",
    "cm = graph.as_default()   \n",
    "cm.__enter__()\n",
    "# module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" \n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" \n",
    "#@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url, trainable=True)\n",
    "\n",
    "session = tf.Session(graph=graph)\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.tables_initializer())\n",
    "input1 = tf.placeholder(tf.string, shape=(None))\n",
    "emb = embed(input1)\n",
    "\n",
    "\n",
    "def encode_USE(texts):   \n",
    "    emb1 = session.run([emb], feed_dict={ input1: texts })\n",
    "    return emb1\n",
    "\n",
    "#warm up\n",
    "_ = encode_USE([\"sasha\", \"miko\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "text_emb_USE = encode_USE(texts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {            \n",
    "    version: '1.0'\n",
    "    encoder: 'USE',\n",
    "    model: 'uncased_L-24_H-1024_A-16',    \n",
    "    max_seq_len: 200,\n",
    "    pooling_strategy: 'REDUCE_MEAN' \n",
    "    pooling_layer: [-1, -2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_emb = list(map(lambda mess,emb: add_emb_to_message(mess, 'text', emb, metadata), zip(messages,text_emb_USE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(m in messages_emb):\n",
    "    db_local.genie_conversation_messages_emb.save(m, check_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
